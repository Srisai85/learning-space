{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scipy: 1.0.0\n",
      "numpy: 1.13.1\n",
      "matplotlib: 2.0.2\n",
      "pandas: 0.20.3\n",
      "statsmodels: 0.8.0\n",
      "sklearn: 0.19.1\n",
      "theano: 0.9.0\n",
      "tensorflow: 1.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras: 2.0.4\n"
     ]
    }
   ],
   "source": [
    "# scipy\n",
    "import scipy\n",
    "print('scipy: %s' % scipy.__version__)\n",
    "# numpy\n",
    "import numpy\n",
    "print('numpy: %s' % numpy.__version__)\n",
    "# matplotlib\n",
    "import matplotlib\n",
    "print('matplotlib: %s' % matplotlib.__version__)\n",
    "# pandas\n",
    "import pandas\n",
    "print('pandas: %s' % pandas.__version__)\n",
    "# statsmodels\n",
    "import statsmodels\n",
    "print('statsmodels: %s' % statsmodels.__version__)\n",
    "# scikit-learn\n",
    "import sklearn\n",
    "print('sklearn: %s' % sklearn.__version__)\n",
    "# theano\n",
    "import theano\n",
    "print('theano: %s' % theano.__version__)\n",
    "# tensorflow\n",
    "import tensorflow\n",
    "print('tensorflow: %s' % tensorflow.__version__)\n",
    "# keras\n",
    "import keras\n",
    "print('keras: %s' % keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-722a0c3dfe12>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-722a0c3dfe12>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    python deep_versions.py\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "python deep_versions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10cd59250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = pandas.read_csv('/Volumes/PANZER/Github/learning-space/Datasets/08 - Time Series/international-airline-passengers.csv', usecols=[1], engine='python', skipfooter=3)\n",
    "plt.plot(dataset)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(120185)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "dataframe = pandas.read_csv('/Volumes/PANZER/Github/learning-space/Datasets/08 - Time Series/international-airline-passengers.csv', usecols=[1], engine='python', skipfooter=3)\n",
    "dataset = dataframe.values\n",
    "dataset = dataset.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 48)\n"
     ]
    }
   ],
   "source": [
    "# split into train and test sets\n",
    "train_size = int(len(dataset) * 0.67)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back-1):\n",
    "\t\ta = dataset[i:(i+look_back), 0]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back, 0])\n",
    "\treturn numpy.array(dataX), numpy.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# reshape into X=t and Y=t+1\n",
    "look_back = 1\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# reshape input to be [samples, time steps, features]\n",
    "trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2s - loss: 0.0154\n",
      "Epoch 2/100\n",
      "0s - loss: 0.0075\n",
      "Epoch 3/100\n",
      "0s - loss: 0.0066\n",
      "Epoch 4/100\n",
      "0s - loss: 0.0058\n",
      "Epoch 5/100\n",
      "0s - loss: 0.0051\n",
      "Epoch 6/100\n",
      "0s - loss: 0.0044\n",
      "Epoch 7/100\n",
      "1s - loss: 0.0038\n",
      "Epoch 8/100\n",
      "1s - loss: 0.0033\n",
      "Epoch 9/100\n",
      "0s - loss: 0.0029\n",
      "Epoch 10/100\n",
      "0s - loss: 0.0026\n",
      "Epoch 11/100\n",
      "0s - loss: 0.0024\n",
      "Epoch 12/100\n",
      "0s - loss: 0.0022\n",
      "Epoch 13/100\n",
      "0s - loss: 0.0021\n",
      "Epoch 14/100\n",
      "0s - loss: 0.0021\n",
      "Epoch 15/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 16/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 17/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 18/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 19/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 20/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 21/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 22/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 23/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 24/100\n",
      "0s - loss: 0.0019\n",
      "Epoch 25/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 26/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 27/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 28/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 29/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 30/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 31/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 32/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 33/100\n",
      "0s - loss: 0.0019\n",
      "Epoch 34/100\n",
      "0s - loss: 0.0021\n",
      "Epoch 35/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 36/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 37/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 38/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 39/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 40/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 41/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 42/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 43/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 44/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 45/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 46/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 47/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 48/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 49/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 50/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 51/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 52/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 53/100\n",
      "0s - loss: 0.0019\n",
      "Epoch 54/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 55/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 56/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 57/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 58/100\n",
      "0s - loss: 0.0019\n",
      "Epoch 59/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 60/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 61/100\n",
      "0s - loss: 0.0019\n",
      "Epoch 62/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 63/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 64/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 65/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 66/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 67/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 68/100\n",
      "0s - loss: 0.0019\n",
      "Epoch 69/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 70/100\n",
      "0s - loss: 0.0019\n",
      "Epoch 71/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 72/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 73/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 74/100\n",
      "0s - loss: 0.0019\n",
      "Epoch 75/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 76/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 77/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 78/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 79/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 80/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 81/100\n",
      "0s - loss: 0.0020\n",
      "Epoch 82/100\n"
     ]
    }
   ],
   "source": [
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(1, look_back)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# make predictions\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "# invert predictions\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([testY])\n",
    "# calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# shift train predictions for plotting\n",
    "trainPredictPlot = numpy.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = numpy.empty_like(dataset)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
    "# plot baseline and predictions\n",
    "plt.plot(scaler.inverse_transform(dataset))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# With Window Method\n",
    "# LSTM for international airline passengers problem with window regression framing\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back-1):\n",
    "\t\ta = dataset[i:(i+look_back), 0]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back, 0])\n",
    "\treturn numpy.array(dataX), numpy.array(dataY)\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "# load the dataset\n",
    "dataframe = read_csv('/Volumes/PANZER/Github/learning-space/Datasets/08 - Time Series/international-airline-passengers.csv', usecols=[1], engine='python', skipfooter=3)\n",
    "dataset = dataframe.values\n",
    "dataset = dataset.astype('float32')\n",
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "# split into train and test sets\n",
    "train_size = int(len(dataset) * 0.67)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "# reshape into X=t and Y=t+1\n",
    "look_back = 3\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "# reshape input to be [samples, time steps, features]\n",
    "trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(1, look_back)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2)\n",
    "# make predictions\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "# invert predictions\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([testY])\n",
    "# calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "# shift train predictions for plotting\n",
    "trainPredictPlot = numpy.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = numpy.empty_like(dataset)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
    "# plot baseline and predictions\n",
    "plt.plot(scaler.inverse_transform(dataset))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# LSTM for international airline passengers problem with time step regression framing\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back-1):\n",
    "\t\ta = dataset[i:(i+look_back), 0]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back, 0])\n",
    "\treturn numpy.array(dataX), numpy.array(dataY)\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "# load the dataset\n",
    "dataframe = read_csv('/Volumes/PANZER/Github/learning-space/Datasets/08 - Time Series/international-airline-passengers.csv', usecols=[1], engine='python', skipfooter=3)\n",
    "dataset = dataframe.values\n",
    "dataset = dataset.astype('float32')\n",
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "# split into train and test sets\n",
    "train_size = int(len(dataset) * 0.67)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "# reshape into X=t and Y=t+1\n",
    "look_back = 3\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "# reshape input to be [samples, time steps, features]\n",
    "trainX = numpy.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n",
    "testX = numpy.reshape(testX, (testX.shape[0], testX.shape[1], 1))\n",
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(look_back, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2)\n",
    "# make predictions\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "# invert predictions\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([testY])\n",
    "# calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "# shift train predictions for plotting\n",
    "trainPredictPlot = numpy.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = numpy.empty_like(dataset)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
    "# plot baseline and predictions\n",
    "plt.plot(scaler.inverse_transform(dataset))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# LSTM for international airline passengers problem with memory\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back-1):\n",
    "\t\ta = dataset[i:(i+look_back), 0]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back, 0])\n",
    "\treturn numpy.array(dataX), numpy.array(dataY)\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "# load the dataset\n",
    "dataframe = read_csv('/Volumes/PANZER/Github/learning-space/Datasets/08 - Time Series/international-airline-passengers.csv', usecols=[1], engine='python', skipfooter=3)\n",
    "dataset = dataframe.values\n",
    "dataset = dataset.astype('float32')\n",
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "# split into train and test sets\n",
    "train_size = int(len(dataset) * 0.67)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "# reshape into X=t and Y=t+1\n",
    "look_back = 3\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "# reshape input to be [samples, time steps, features]\n",
    "trainX = numpy.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n",
    "testX = numpy.reshape(testX, (testX.shape[0], testX.shape[1], 1))\n",
    "# create and fit the LSTM network\n",
    "batch_size = 1\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, batch_input_shape=(batch_size, look_back, 1), stateful=True))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "for i in range(100):\n",
    "\tmodel.fit(trainX, trainY, epochs=1, batch_size=batch_size, verbose=2, shuffle=False)\n",
    "\tmodel.reset_states()\n",
    "# make predictions\n",
    "trainPredict = model.predict(trainX, batch_size=batch_size)\n",
    "model.reset_states()\n",
    "testPredict = model.predict(testX, batch_size=batch_size)\n",
    "# invert predictions\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([testY])\n",
    "# calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "# shift train predictions for plotting\n",
    "trainPredictPlot = numpy.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = numpy.empty_like(dataset)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
    "# plot baseline and predictions\n",
    "plt.plot(scaler.inverse_transform(dataset))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Stacked LSTM for international airline passengers problem with memory\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back-1):\n",
    "\t\ta = dataset[i:(i+look_back), 0]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back, 0])\n",
    "\treturn numpy.array(dataX), numpy.array(dataY)\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "# load the dataset\n",
    "dataframe = read_csv('/Volumes/PANZER/Github/learning-space/Datasets/08 - Time Series/international-airline-passengers.csv', usecols=[1], engine='python', skipfooter=3)\n",
    "dataset = dataframe.values\n",
    "dataset = dataset.astype('float32')\n",
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "# split into train and test sets\n",
    "train_size = int(len(dataset) * 0.67)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "# reshape into X=t and Y=t+1\n",
    "look_back = 3\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "# reshape input to be [samples, time steps, features]\n",
    "trainX = numpy.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n",
    "testX = numpy.reshape(testX, (testX.shape[0], testX.shape[1], 1))\n",
    "# create and fit the LSTM network\n",
    "batch_size = 1\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, batch_input_shape=(batch_size, look_back, 1), stateful=True, return_sequences=True))\n",
    "model.add(LSTM(4, batch_input_shape=(batch_size, look_back, 1), stateful=True))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "for i in range(100):\n",
    "\tmodel.fit(trainX, trainY, epochs=1, batch_size=batch_size, verbose=2, shuffle=False)\n",
    "\tmodel.reset_states()\n",
    "# make predictions\n",
    "trainPredict = model.predict(trainX, batch_size=batch_size)\n",
    "model.reset_states()\n",
    "testPredict = model.predict(testX, batch_size=batch_size)\n",
    "# invert predictions\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([testY])\n",
    "# calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "# shift train predictions for plotting\n",
    "trainPredictPlot = numpy.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = numpy.empty_like(dataset)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
    "# plot baseline and predictions\n",
    "plt.plot(scaler.inverse_transform(dataset))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "import numpy\n",
    "\n",
    "# date-time parsing function for loading the dataset\n",
    "def parser(x):\n",
    "\treturn datetime.strptime('190'+x, '%Y-%m')\n",
    "\n",
    "# frame a sequence as a supervised learning problem\n",
    "def timeseries_to_supervised(data, lag=1):\n",
    "\tdf = DataFrame(data)\n",
    "\tcolumns = [df.shift(i) for i in range(1, lag+1)]\n",
    "\tcolumns.append(df)\n",
    "\tdf = concat(columns, axis=1)\n",
    "\tdf.fillna(0, inplace=True)\n",
    "\treturn df\n",
    "\n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn Series(diff)\n",
    "\n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "\treturn yhat + history[-interval]\n",
    "\n",
    "# scale train and test data to [-1, 1]\n",
    "def scale(train, test):\n",
    "\t# fit scaler\n",
    "\tscaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\tscaler = scaler.fit(train)\n",
    "\t# transform train\n",
    "\ttrain = train.reshape(train.shape[0], train.shape[1])\n",
    "\ttrain_scaled = scaler.transform(train)\n",
    "\t# transform test\n",
    "\ttest = test.reshape(test.shape[0], test.shape[1])\n",
    "\ttest_scaled = scaler.transform(test)\n",
    "\treturn scaler, train_scaled, test_scaled\n",
    "\n",
    "# inverse scaling for a forecasted value\n",
    "def invert_scale(scaler, X, value):\n",
    "\tnew_row = [x for x in X] + [value]\n",
    "\tarray = numpy.array(new_row)\n",
    "\tarray = array.reshape(1, len(array))\n",
    "\tinverted = scaler.inverse_transform(array)\n",
    "\treturn inverted[0, -1]\n",
    "\n",
    "# fit an LSTM network to training data\n",
    "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
    "\tX, y = train[:, 0:-1], train[:, -1]\n",
    "\tX = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "\tmodel.add(Dense(1))\n",
    "\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\tfor i in range(nb_epoch):\n",
    "\t\tmodel.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n",
    "\t\tmodel.reset_states()\n",
    "\treturn model\n",
    "\n",
    "# make a one-step forecast\n",
    "def forecast_lstm(model, batch_size, X):\n",
    "\tX = X.reshape(1, 1, len(X))\n",
    "\tyhat = model.predict(X, batch_size=batch_size)\n",
    "\treturn yhat[0,0]\n",
    "\n",
    "# load dataset\n",
    "series = read_csv('/Volumes/PANZER/Github/learning-space/Datasets/08 - Time Series/shampoo-sales.csv', header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)\n",
    "\n",
    "# transform data to be stationary\n",
    "raw_values = series.values\n",
    "diff_values = difference(raw_values, 1)\n",
    "\n",
    "# transform data to be supervised learning\n",
    "supervised = timeseries_to_supervised(diff_values, 1)\n",
    "supervised_values = supervised.values\n",
    "\n",
    "# split data into train and test-sets\n",
    "train, test = supervised_values[0:-12], supervised_values[-12:]\n",
    "\n",
    "# transform the scale of the data\n",
    "scaler, train_scaled, test_scaled = scale(train, test)\n",
    "\n",
    "# repeat experiment\n",
    "repeats = 30\n",
    "error_scores = list()\n",
    "for r in range(repeats):\n",
    "\t# fit the model\n",
    "\tlstm_model = fit_lstm(train_scaled, 1, 3000, 4)\n",
    "\t# forecast the entire training dataset to build up state for forecasting\n",
    "\ttrain_reshaped = train_scaled[:, 0].reshape(len(train_scaled), 1, 1)\n",
    "\tlstm_model.predict(train_reshaped, batch_size=1)\n",
    "\t# walk-forward validation on the test data\n",
    "\tpredictions = list()\n",
    "\tfor i in range(len(test_scaled)):\n",
    "\t\t# make one-step forecast\n",
    "\t\tX, y = test_scaled[i, 0:-1], test_scaled[i, -1]\n",
    "\t\tyhat = forecast_lstm(lstm_model, 1, X)\n",
    "\t\t# invert scaling\n",
    "\t\tyhat = invert_scale(scaler, X, yhat)\n",
    "\t\t# invert differencing\n",
    "\t\tyhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "\t\t# store forecast\n",
    "\t\tpredictions.append(yhat)\n",
    "\t# report performance\n",
    "\trmse = sqrt(mean_squared_error(raw_values[-12:], predictions))\n",
    "\tprint('%d) Test RMSE: %.3f' % (r+1, rmse))\n",
    "\terror_scores.append(rmse)\n",
    "\n",
    "# summarize results\n",
    "results = DataFrame()\n",
    "results['rmse'] = error_scores\n",
    "print(results.describe())\n",
    "results.boxplot()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#multi-step persistence forecast is li\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# date-time parsing function for loading the dataset\n",
    "def parser(x):\n",
    "\treturn datetime.strptime('190'+x, '%Y-%m')\n",
    "\n",
    "# convert time series into supervised learning problem\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n",
    "\n",
    "# transform series into train and test sets for supervised learning\n",
    "def prepare_data(series, n_test, n_lag, n_seq):\n",
    "\t# extract raw values\n",
    "\traw_values = series.values\n",
    "\traw_values = raw_values.reshape(len(raw_values), 1)\n",
    "\t# transform into supervised learning problem X, y\n",
    "\tsupervised = series_to_supervised(raw_values, n_lag, n_seq)\n",
    "\tsupervised_values = supervised.values\n",
    "\t# split into train and test sets\n",
    "\ttrain, test = supervised_values[0:-n_test], supervised_values[-n_test:]\n",
    "\treturn train, test\n",
    "\n",
    "# make a persistence forecast\n",
    "def persistence(last_ob, n_seq):\n",
    "\treturn [last_ob for i in range(n_seq)]\n",
    "\n",
    "# evaluate the persistence model\n",
    "def make_forecasts(train, test, n_lag, n_seq):\n",
    "\tforecasts = list()\n",
    "\tfor i in range(len(test)):\n",
    "\t\tX, y = test[i, 0:n_lag], test[i, n_lag:]\n",
    "\t\t# make forecast\n",
    "\t\tforecast = persistence(X[-1], n_seq)\n",
    "\t\t# store the forecast\n",
    "\t\tforecasts.append(forecast)\n",
    "\treturn forecasts\n",
    "\n",
    "# evaluate the RMSE for each forecast time step\n",
    "def evaluate_forecasts(test, forecasts, n_lag, n_seq):\n",
    "\tfor i in range(n_seq):\n",
    "\t\tactual = test[:,(n_lag+i)]\n",
    "\t\tpredicted = [forecast[i] for forecast in forecasts]\n",
    "\t\trmse = sqrt(mean_squared_error(actual, predicted))\n",
    "\t\tprint('t+%d RMSE: %f' % ((i+1), rmse))\n",
    "\n",
    "# plot the forecasts in the context of the original dataset\n",
    "def plot_forecasts(series, forecasts, n_test):\n",
    "\t# plot the entire dataset in blue\n",
    "\tpyplot.plot(series.values)\n",
    "\t# plot the forecasts in red\n",
    "\tfor i in range(len(forecasts)):\n",
    "\t\toff_s = len(series) - n_test + i - 1\n",
    "\t\toff_e = off_s + len(forecasts[i]) + 1\n",
    "\t\txaxis = [x for x in range(off_s, off_e)]\n",
    "\t\tyaxis = [series.values[off_s]] + forecasts[i]\n",
    "\t\tpyplot.plot(xaxis, yaxis, color='red')\n",
    "\t# show the plot\n",
    "\tpyplot.show()\n",
    "\n",
    "# load dataset\n",
    "series = read_csv('/Volumes/PANZER/Github/learning-space/Datasets/08 - Time Series/shampoo-sales.csv', header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)\n",
    "# configure\n",
    "n_lag = 1\n",
    "n_seq = 3\n",
    "n_test = 10\n",
    "# prepare data\n",
    "train, test = prepare_data(series, n_test, n_lag, n_seq)\n",
    "# make forecasts\n",
    "forecasts = make_forecasts(train, test, n_lag, n_seq)\n",
    "# evaluate forecasts\n",
    "evaluate_forecasts(test, forecasts, n_lag, n_seq)\n",
    "# plot forecasts\n",
    "plot_forecasts(series, forecasts, n_test+2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
